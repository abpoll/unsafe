% Generated by Paperpile. Check out https://paperpile.com for more information.
% BibTeX export options can be customized via Settings -> BibTeX.

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Rozer2019,
  title     = "Probabilistic models significantly reduce uncertainty in
               Hurricane Harvey pluvial flood loss estimates",
  author    = "R{\"o}zer, V and Kreibich, H and Schr{\"o}ter, K and M{\"u}ller,
               M and {others}",
  abstract  = "Pluvial flood risk is mostly excluded in urban flood risk
               assessment. However, the risk of pluvial flooding is a growing
               challenge with a projected increase of extreme rainstorms …",
  journal   = "Earth's",
  publisher = "Wiley Online Library",
  year      =  2019,
  url       = "https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/2018EF001074",
  keywords  = "unsafe\_joss"
}

@ARTICLE{Condon2023,
  title    = "Climate Services: The Business of Physical Risk",
  author   = "Condon, Madison",
  abstract = "A growing number of investors, insurers, financial services
              providers, and nonprofits rely on information about localized
              physical climate risks, like floods, hurricanes, and wildfires.
              The outcomes of these risk projections have significant
              consequences in the economy, including allocating investment
              capital, impacting housing prices and demographic shifts, and
              prioritizing adaptation infrastructure projects. The climate risk
              information available to individual citizens and municipalities,
              however, is limited and expensive to access. Further, many
              providers of climate services use black box models that make
              overseeing the scientific rigor of their methodologies
              impossible--- a concern given scientific critiques that many may
              be obfuscating the uncertainty in their projections.
              Municipalities that want to challenge insurance and bond rating
              determinations must rally significant resources for modeling and
              data, a scattershot policing method at best. And when companies
              have access to sophisticated modeling about future impacts---
              some of them potentially devastating for entire communities---the
              decision to share that information has been largely left up to
              the corporation.This Article argues that actionable and
              transparent information about our climate-changed future is a
              public good that the private sector cannot be depended upon to
              provide equitably or reliably. Further, all private climate
              services rely on upstream climate data and models that were
              collected and produced by an enormous network of public
              institutions. There are important lessons to be learned from the
              recent success of special interests in pressing for the
              privatization of weather data and services---a trend that has
              knock-on effects for weather forecasts globally. This Article
              urges state and federal governments to invest in their own
              climate services capacity at a scale not currently contemplated.
              Risk assessments lacking a scientific basis can lead to
              maladaptation across the economy. While it is a potentially
              limited matter of consumer protection or tort liability when a
              consultancy over-promises its analytical capabilities, it is a
              much larger problem if regulators themselves misunderstand the
              limits of uncertainty when designing risk oversight.",
  journal  = "Ariz. State Law J.",
  volume   =  55,
  number   =  147,
  month    =  mar,
  year     =  2023,
  url      = "https://papers.ssrn.com/abstract=4396826",
  keywords = "physical risk, climate change, ratings agencies, municipal bonds,
              open data;unsafe\_joss",
  issn     = "0164-4297",
  doi      = "10.2139/ssrn.4396826"
}

@ARTICLE{Bates2023,
  title     = "Fundamental limits to flood inundation modelling",
  author    = "Bates, Paul",
  abstract  = "Can flood hazards be predicted precisely and accurately at the
               scale of individual buildings? A consideration of the
               uncertainties in most inundation modelling suggests not.",
  journal   = "Nature Water",
  publisher = "Nature Publishing Group",
  volume    =  1,
  number    =  7,
  pages     = "566-567",
  month     =  jul,
  year      =  2023,
  url       = "https://www.nature.com/articles/s44221-023-00106-4",
  keywords  = "unsafe\_joss",
  language  = "en",
  issn      = "2731-6084, 2731-6084",
  doi       = "10.1038/s44221-023-00106-4"
}

@ARTICLE{Hosseini-Shakib2024,
  title    = "What drives uncertainty surrounding riverine flood risks?",
  author   = "Hosseini-Shakib, Iman and Alipour, Atieh and Seiyon Lee, Benjamin
              and Srikrishnan, Vivek and Nicholas, Robert E and Keller, Klaus
              and Sharma, Sanjib",
  abstract = "Designing strategies to manage flood risks is complicated by the
              often large uncertainties surrounding flood risk projections.
              Uncertainty surrounding riverine flood risks can stem from
              choices regarding boundary and initial conditions, model
              structures, and parameters as well as interactions among hazards,
              exposures, and vulnerabilities. Here we analyze a case study to
              rank the drivers of uncertainties surrounding riverine flood
              hazards and risks. Using Sobol' sensitivity analysis with a large
              number of simulations, we thoroughly explore the interactions
              among different sources of uncertainty. We find that the
              projected flood risk is most sensitive to factors associated with
              flood hazards, rather than exposure and vulnerability: upstream
              discharge, river bed elevation, channel roughness, and the
              digital elevation model resolution. Our results highlight the
              importance of uncertainty quantification in enhancing the
              reliability of flood models and risk assessments.",
  journal  = "J. Hydrol.",
  volume   =  634,
  pages    = "131055",
  month    =  may,
  year     =  2024,
  url      = "https://www.sciencedirect.com/science/article/pii/S0022169424004505",
  keywords = "Riverine flooding; Flood risk modeling; Global sensitivity
              analysis; Uncertainty analysis;unsafe\_joss",
  issn     = "0022-1694",
  doi      = "10.1016/j.jhydrol.2024.131055"
}

@ARTICLE{Xia2024,
  title    = "Computer vision based first floor elevation estimation from
              mobile {LiDAR} data",
  author   = "Xia, Jiahao and Gong, Jie",
  abstract = "First Floor Elevation (FFE) of a house is crucial information for
              flood management and for accurately assessing the flood exposure
              risk of a property. However, the lack of reliable FFE data on a
              large geographic scale significantly limits efforts to mitigate
              flood risk, such as decision on elevating a property. The
              traditional method of collecting elevation data of a house relies
              on time-consuming and labor-intensive on-site inspections
              conducted by licensed surveyors or engineers. In this paper, we
              propose an automated and scalable method for extracting FFE from
              mobile LiDAR point cloud data. The fine-tuned yolov5 model is
              employed to detect doors, windows, and garage doors on the
              intensity-based projection of the point cloud, achieving an
              mAP@0.5:0.95 of 0.689. Subsequently, FFE is estimated using
              detected objects. We evaluated the Median Absolute Error (MAE)
              metric for the estimated FFE in Manville, Ventnor, and Longport,
              which resulted in values of 0.2 ft, 0.27 ft, and 0.24 ft,
              respectively. The availability of FFE data has the potential to
              provide valuable guidance for setting flood insurance premiums
              and facilitating benefit-cost analyses of buyout programs
              targeting residential buildings with a high flood risk.",
  journal  = "Autom. Constr.",
  volume   =  159,
  pages    = "105258",
  month    =  mar,
  year     =  2024,
  url      = "https://www.sciencedirect.com/science/article/pii/S0926580523005186",
  keywords = "First floor elevation; Computer vision; Mobile LiDAR; Flood risk
              and mitigation;unsafe\_joss",
  issn     = "0926-5805",
  doi      = "10.1016/j.autcon.2023.105258"
}

% The entry below contains non-ASCII chars that could not be converted
% to a LaTeX equivalent.
@ARTICLE{Saint-Geours2015,
  title     = "Ranking sources of uncertainty in flood damage modelling: a case
               study on the cost‐benefit analysis of a flood mitigation project
               in the Orb Delta, France",
  author    = "Saint-Geours, N and Grelot, F and Bailly, J-S and Lavergne, C",
  abstract  = "AbstractCost‐benefit analyses (CBA) of flood management plans
               usually require estimating expected annual flood damages on a
               study area and rely on a complex modelling chain, including
               hydrological, hydraulic and economic modelling, as well as
               geographic information system‐based spatial analysis. As most
               model‐based assessments, these CBA are fraught with uncertainty.
               In this paper, we consider as a case study the CBA of a set of
               flood control structural measures on the Orb Delta, France. We
               demonstrate the use of variance‐based global sensitivity
               analysis to (i) propagate uncertainty sources through the
               modelling chain and assess their overall impact on the outcomes
               of the CBA, and (ii) rank uncertainty sources according to their
               contribution to the variance of the CBA outcomes. All
               uncertainty sources prove to explain a significant share of the
               overall output variance. Results show that the ranking of
               uncertainty sources depends not only on the economic sector
               considered (private housing, agricultural land, other economic
               activities), but also on a number of averaging‐out effects
               controlled by the number and surface area of the assets
               considered, the number of land use types or the number of damage
               functions.",
  journal   = "J. Flood Risk Manag.",
  publisher = "Wiley",
  volume    =  8,
  number    =  2,
  pages     = "161-176",
  month     =  jun,
  year      =  2015,
  url       = "https://onlinelibrary.wiley.com/doi/10.1111/jfr3.12068",
  keywords  = "unsafe\_joss",
  copyright = "http://onlinelibrary.wiley.com/termsAndConditions\#vor",
  language  = "en",
  issn      = "1753-318X",
  doi       = "10.1111/jfr3.12068"
}

@ARTICLE{Kousky2020,
  title     = "Flood Risk and the {U.S}. Housing Market",
  author    = "Kousky, Carolyn and Kunreuther, Howard and LaCour-Little,
               Michael and Wachter, Susan",
  abstract  = "Flooding is the most frequent and costliest natural disaster in
               the United States, yet most households are uninsured or
               underinsured against flood and may incorrectly expect that
               government agencies provide sufficient post-flood assistance.
               This paper synthesizes existing research on flood risks, flood
               insurance, and their impacts on the U.S. housing market. We
               focus on the single-family market segment, as primary residences
               tend to be the largest category of wealth for most households.
               We conclude with policy implications and suggestions for future
               research.",
  journal   = "Journal of Housing Research",
  publisher = "Routledge",
  volume    =  29,
  number    = "sup1",
  pages     = "S3-S24",
  month     =  dec,
  year      =  2020,
  url       = "https://doi.org/10.1080/10527001.2020.1836915",
  keywords  = "unsafe\_joss",
  issn      = "1052-7001",
  doi       = "10.1080/10527001.2020.1836915"
}

@ARTICLE{Krause2020,
  title     = "Uncertainty in automated valuation models: Error-based versus
               model-based approaches",
  author    = "Krause, A and Martin, A and Fix, M",
  abstract  = "ABSTRACTPoint estimates from Automated Valuation Models (AVMs)
               represent the most likely value from a distribution of possible
               values. The uncertainty in the point estimate ? the width of the
               range of possible values at a given level of confidence ? is a
               critical piece of the AVM output, especially in collateral and
               transactional situations. Estimating AVM uncertainty, however,
               remains highly unstandardised in both terminology and methods.
               In this paper, we present and compare two of the most common
               approaches to estimating AVM uncertainty ? model-based and
               error-based prediction intervals. We also present a uniform
               language and framework for evaluating the calibration and
               efficiency of uncertainty estimates. Based on empirical tests on
               a large, longitudinal dataset of home sales, we show that
               model-based approaches outperform error-based ones in all but
               cases with very highest confidence level requirements. The
               differences between the two methods are conditioned on model
               class, geographic data partitions and data filtering conditions.",
  journal   = "Journal of Property Research",
  publisher = "Routledge",
  volume    =  37,
  number    =  4,
  pages     = "308-339",
  month     =  oct,
  year      =  2020,
  url       = "https://doi.org/10.1080/09599916.2020.1807587",
  keywords  = "unsafe\_joss",
  issn      = "0959-9916",
  doi       = "10.1080/09599916.2020.1807587"
}

@ARTICLE{Mulder2023,
  title    = "Risk Rating without Information Provision",
  author   = "Mulder, Philip and Kousky, Carolyn",
  abstract = "Risk Rating without Information Provision by Philip Mulder and
              Carolyn Kousky. Published in volume 113, pages 299-303 of AEA
              Papers and Proceedings, May 2023, Abstract: We describe the
              initial impact of risk-based flood insurance pricing in the
              United States. More than two-thirds of National Flood I...",
  journal  = "AEA Papers and Proceedings",
  volume   =  113,
  pages    = "299-303",
  month    =  may,
  year     =  2023,
  url      = "https://www.aeaweb.org/articles?id=10.1257/pandp.20231102&ArticleSearch%5Bwithin%5D%5Barticletitle%5D=1&ArticleSearch%5Bwithin%5D%5Barticleabstract%5D=1&ArticleSearch%5Bwithin%5D%5Bauthorlast%5D=1&ArticleSearch%5Bq%5D=kousky&JelClass%5Bvalue%5D=0",
  keywords = "unsafe\_joss",
  issn     = "2574-0768",
  doi      = "10.1257/pandp.20231102"
}

@ARTICLE{Sieg2023,
  title     = "Toward an adequate level of detail in flood risk assessments",
  author    = "Sieg, Tobias and Kienzler, Sarah and R{\"o}zer, Viktor and
               Vogel, Kristin and Rust, Henning and Bronstert, Axel and
               Kreibich, Heidi and Merz, Bruno and Thieken, Annegret H",
  abstract  = "Abstract Flood risk assessments require different disciplines to
               understand and model the underlying components hazard, exposure,
               and vulnerability. Many methods and data sets have been refined
               considerably to cover more details of spatial, temporal, or
               process information. We compile case studies indicating that
               refined methods and data have a considerable effect on the
               overall assessment of flood risk. But are these improvements
               worth the effort? The adequate level of detail is typically
               unknown and prioritization of improvements in a specific
               component is hampered by the lack of an overarching view on
               flood risk. Consequently, creating the dilemma of potentially
               being too greedy or too wasteful with the resources available
               for a risk assessment. A ?sweet spot? between those two would
               use methods and data sets that cover all relevant known
               processes without using resources inefficiently. We provide
               three key questions as a qualitative guidance toward this ?sweet
               spot.? For quantitative decision support, more overarching case
               studies in various contexts are needed to reveal the sensitivity
               of the overall flood risk to individual components. This could
               also support the anticipation of unforeseen events like the
               flood event in Germany and Belgium in 2021 and increase the
               reliability of flood risk assessments.",
  journal   = "J. Flood Risk Manag.",
  publisher = "Wiley",
  month     =  apr,
  year      =  2023,
  url       = "https://onlinelibrary.wiley.com/doi/10.1111/jfr3.12889",
  keywords  = "unsafe\_joss",
  copyright = "http://creativecommons.org/licenses/by/4.0/",
  language  = "en",
  issn      = "1753-318X",
  doi       = "10.1111/jfr3.12889"
}

@ARTICLE{Wing2020,
  title    = "New insights into {US} flood vulnerability revealed from flood
              insurance big data",
  author   = "Wing, Oliver E J and Pinter, Nicholas and Bates, Paul D and
              Kousky, Carolyn",
  abstract = "Improvements in modelling power and input data have vastly
              improved the precision of physical flood models, but translation
              into economic outputs requires depth-damage functions that are
              inadequately verified. In particular, flood damage is widely
              assumed to increase monotonically with water depth. Here, we
              assess flood vulnerability in the US using >2 million claims from
              the National Flood Insurance Program (NFIP). NFIP claims data are
              messy, but the size of the dataset provides powerful empirical
              tests of damage patterns and modelling approaches. We show that
              current depth-damage functions consist of disparate relationships
              that match poorly with observations. Observed flood losses are
              not monotonic functions of depth, but instead better follow a
              beta function, with bimodal distributions for different water
              depths. Uncertainty in flood losses has been called the main
              bottleneck in flood risk studies, an obstacle that may be
              remedied using large-scale empirical flood damage data.",
  journal  = "Nat. Commun.",
  volume   =  11,
  number   =  1,
  pages    = "1444",
  month    =  mar,
  year     =  2020,
  url      = "http://dx.doi.org/10.1038/s41467-020-15264-2",
  keywords = "unsafe\_joss;Uncertain Flood Risk Estimation",
  language = "en",
  issn     = "2041-1723",
  pmid     = "32193386",
  doi      = "10.1038/s41467-020-15264-2",
  pmc      = "PMC7081335"
}

@ARTICLE{Merz2010,
  title     = "Review article ``Assessment of economic flood damage''",
  author    = "Merz, B and Kreibich, H and Schwarze, R and Thieken, A",
  abstract  = "Abstract. Damage assessments of natural hazards supply crucial
               information to decision support and policy development in the
               fields of natural hazard management and adaptation planning to
               climate change. Specifically, the estimation of economic flood
               damage is gaining greater importance as flood risk management is
               becoming the dominant approach of flood control policies
               throughout Europe. This paper reviews the state-of-the-art and
               identifies research directions of economic flood damage
               assessment. Despite the fact that considerable research effort
               has been spent and progress has been made on damage data
               collection, data analysis and model development in recent years,
               there still seems to be a mismatch between the relevance of
               damage assessments and the quality of the available models and
               datasets. Often, simple approaches are used, mainly due to
               limitations in available data and knowledge on damage
               mechanisms. The results of damage assessments depend on many
               assumptions, e.g. the selection of spatial and temporal
               boundaries, and there are many pitfalls in economic evaluation,
               e.g. the choice between replacement costs or depreciated values.
               Much larger efforts are required for empirical and synthetic
               data collection and for providing consistent, reliable data to
               scientists and practitioners. A major shortcoming of damage
               modelling is that model validation is scarcely performed.
               Uncertainty analyses and thorough scrutiny of model inputs and
               assumptions should be mandatory for each damage model
               development and application, respectively. In our view, flood
               risk assessments are often not well balanced. Much more
               attention is given to the hazard assessment part, whereas damage
               assessment is treated as some kind of appendix within the risk
               analysis. Advances in flood damage assessment could trigger
               subsequent methodological improvements in other natural hazard
               areas with comparable time-space properties.",
  journal   = "Nat. Hazards Earth Syst. Sci.",
  publisher = "Copernicus GmbH",
  volume    =  10,
  number    =  8,
  pages     = "1697-1724",
  month     =  aug,
  year      =  2010,
  url       = "https://nhess.copernicus.org/articles/10/1697/2010/",
  keywords  = "unsafe\_joss;Uncertain Flood Risk Estimation",
  copyright = "https://creativecommons.org/licenses/by/3.0/",
  language  = "en",
  issn      = "1561-8633, 1684-9981",
  doi       = "10.5194/nhess-10-1697-2010"
}

@ARTICLE{Trigg2016,
  title     = "The credibility challenge for global fluvial flood risk analysis",
  author    = "Trigg, M A and Birch, C E and Neal, J C and Bates, P D and
               Smith, A and Sampson, C C and Yamazaki, D and Hirabayashi, Y and
               Pappenberger, F and Dutra, E and Ward, P J and Winsemius, H C
               and Salamon, P and Dottori, F and Rudari, R and Kappes, M S and
               Simpson, A L and Hadzilacos, G and Fewtrell, T J",
  abstract  = "Quantifying flood hazard is an essential component of resilience
               planning, emergency response, and mitigation, including
               insurance. Traditionally undertaken at catchment and national
               scales, recently, efforts have intensified to estimate flood
               risk globally to better allow consistent and equitable decision
               making. Global flood hazard models are now a practical reality,
               thanks to improvements in numerical algorithms, global datasets,
               computing power, and coupled modelling frameworks. Outputs of
               these models are vital for consistent quantification of global
               flood risk and in projecting the impacts of climate change.
               However, the urgency of these tasks means that outputs are being
               used as soon as they are made available and before such methods
               have been adequately tested. To address this, we compare
               multi-probability flood hazard maps for Africa from six global
               models and show wide variation in their flood hazard, economic
               loss and exposed population estimates, which has serious
               implications for model credibility. While there is around
               30\%--40\% agreement in flood extent, our results show that even
               at continental scales, there are significant differences in
               hazard magnitude and spatial pattern between models, notably in
               deltas, arid/semi-arid zones and wetlands. This study is an
               important step towards a better understanding of modelling
               global flood hazard, which is urgently required for both current
               risk and climate change projections.",
  journal   = "Environ. Res. Lett.",
  publisher = "IOP Publishing",
  volume    =  11,
  number    =  9,
  pages     = "094014",
  month     =  sep,
  year      =  2016,
  url       = "https://iopscience.iop.org/article/10.1088/1748-9326/11/9/094014/meta",
  keywords  = "unsafe\_joss",
  language  = "en",
  issn      = "1748-9326",
  doi       = "10.1088/1748-9326/11/9/094014"
}

@ARTICLE{Tate2015,
  title     = "Uncertainty and sensitivity analysis of the {HAZUS-MH} flood
               model",
  author    = "Tate, Eric and Mu{\~n}oz, Cristina and Suchan, Jared",
  journal   = "Nat. Hazards Rev.",
  publisher = "American Society of Civil Engineers (ASCE)",
  volume    =  16,
  number    =  3,
  pages     = "04014030",
  month     =  aug,
  year      =  2015,
  url       = "https://www.researchgate.net/profile/Jared-Suchan-2/publication/276120649_Uncertainty_and_Sensitivity_Analysis_of_the_HAZUS-MH_Flood_Model/links/5dccccf7a6fdcc7e137e4410/Uncertainty-and-Sensitivity-Analysis-of-the-HAZUS-MH-Flood-Model.pdf?_sg%5B0%5D=started_experiment_milestone&origin=journalDetail",
  keywords  = "unsafe\_joss",
  language  = "en",
  issn      = "1527-6988, 1527-6996",
  doi       = "10.1061/(asce)nh.1527-6996.0000167"
}

@ARTICLE{Pollack2022,
  title     = "Aggregation bias and its drivers in large scale flood loss
               estimation: A Massachusetts case study",
  author    = "Pollack, Adam B and Sue Wing, Ian and Nolte, Christoph",
  abstract  = "Abstract Large-scale estimations of flood losses are often based
               on spatially aggregated inputs. This makes risk assessments
               vulnerable to aggregation bias, a well-studied, sometimes
               substantial outcome in analyses that model fine-grained spatial
               phenomena at coarse spatial units. To evaluate this potential in
               the context of large-scale flood risk assessments, we use data
               from a high-resolution flood hazard model and structure
               inventory for over 1.3 million properties in Massachusetts and
               examine how prominent data aggregation approaches affect the
               magnitude and spatial distribution of flood loss estimates. All
               considered aggregation approaches rely on aggregate structure
               inventories but differ in whether flood hazard is also
               aggregated. We find that aggregating only structure inventories
               slightly underestimates overall losses (?10\% bias), and when
               flood hazard data is spatially aggregated to even relatively
               small spatial units (census block), statewide aggregation bias
               can reach +366\%. All aggregation-based procedures fail to
               capture the spatial covariation of inputs distributions in the
               upper tails that disproportionately generate total expected
               losses. Our findings are robust to several key assumptions, add
               important context to published risk assessments and highlight
               opportunities to improve flood loss estimation uncertainty
               quantification.",
  journal   = "J. Flood Risk Manag.",
  publisher = "Wiley",
  volume    =  15,
  number    =  4,
  month     =  dec,
  year      =  2022,
  url       = "https://onlinelibrary.wiley.com/doi/10.1111/jfr3.12851",
  keywords  = "my-papers;unsafe\_joss",
  copyright = "http://creativecommons.org/licenses/by-nc/4.0/",
  issn      = "1753-318X",
  doi       = "10.1111/jfr3.12851"
}

@ARTICLE{Wing2022,
  title     = "Inequitable patterns of {US} flood risk in the Anthropocene",
  author    = "Wing, Oliver E J and Lehman, William and Bates, Paul D and
               Sampson, Christopher C and Quinn, Niall and Smith, Andrew M and
               Neal, Jeffrey C and Porter, Jeremy R and Kousky, Carolyn",
  abstract  = "Current flood risk mapping, relying on historical observations,
               fails to account for increasing threat under climate change.
               Incorporating recent developments in inundation modelling, here
               we show a 26.4\% (24.1--29.1\%) increase in US flood risk by
               2050 due to climate change alone under RCP4.5. Our national
               depiction of comprehensive and high-resolution flood risk
               estimates in the United States indicates current average annual
               losses of US$32.1 billion (US$30.5--33.8 billion) in 2020's
               climate, which are borne disproportionately by poorer
               communities with a proportionally larger White population. The
               future increase in risk will disproportionately impact Black
               communities, while remaining concentrated on the Atlantic and
               Gulf coasts. Furthermore, projected population change (SSP2)
               could cause flood risk increases that outweigh the impact of
               climate change fourfold. These results make clear the need for
               adaptation to flood and emergent climate risks in the United
               States, with mitigation required to prevent the acceleration of
               these risks. Climate change is increasing flood risk, yet models
               based on historical data alone cannot capture the impact.
               Granular mapping of national flood risk shows that losses caused
               by flooding in the United States will increase substantially by
               2050 and disproportionately burden less advantaged communities.",
  journal   = "Nat. Clim. Chang.",
  publisher = "Nature Publishing Group",
  volume    =  12,
  number    =  2,
  pages     = "156-162",
  month     =  jan,
  year      =  2022,
  url       = "https://www.nature.com/articles/s41558-021-01265-6",
  keywords  = "unsafe\_joss;Uncertain Flood Risk Estimation;Measuring Equity
               Literature Review",
  language  = "en",
  issn      = "1758-678X",
  doi       = "10.1038/s41558-021-01265-6"
}

@ARTICLE{Schneider2006,
  title     = "{HAZUS---Its} Development and Its Future",
  author    = "{Schneider Philip J.} and {Schauer Barbara A.}",
  abstract  = "HAZUS development began in the early 1990s and continues to this
               day as the second maintenance release of HAZUS-MH nears
               completion. This paper discusses the history of HAZUS
               development and plans for the future. HAZUS was created with a
               process that included state-of-the-art review of earthquake loss
               estimation methods, followed by methodology and software
               development, and pilot testing. The model was first released for
               earthquakes in 1997, and consisted of an inventory database,
               ground motion model, building and lifeline damage models, fire
               following model, direct and indirect economic loss models, and
               casualties model. Subsequent enhancements included a new bridge
               damage model and a single/group building analysis model.
               Development of the full earthquake, flood and hurricane-capable
               HAZUS began in 1997, with release as HAZUS-MH in early 2004. The
               Flood Model included methods for assessing riverine and coastal
               flooding damage to buildings, transportation and utility
               lifelines, agricultural areas and vehicles, and debris
               generation, and shelter requirements. Effects of flood warning
               were taken into account, as were flow velocity effects. In 2002,
               prior to release of the full Flood Model, a Flood Information
               Tool was released to allow users to begin collecting and sorting
               local flood hazard data, as well as other pertinent data, for
               Level 2 analyses. The Hurricane Model adapted an existing
               peer-reviewed and validated model that describes the entire
               track and wind field of a hurricane or tropical storm as the
               basis for hazard characterization. Methods for assessing
               building damage, building and tree debris and shelter needs are
               also included in the Hurricane Model. Throughout the history of
               HAZUS, inventory data and methodology development always have
               been mirrored by software implementation efforts, such as
               InCAST, which facilitates development and organization of
               databases for creating building portfolios, and Building Data
               Import Tool (BIT), which allows easy import of tax assessors
               data. The release of HAZUS-MH was followed in early 2005 by the
               first maintenance release, HAZUS-MH MR1. Currently, four
               additional releases are anticipated. HAZUS was used in 2001 to
               estimate annualized earthquake losses for the United States.
               Annualized studies for all three hazards are currently being
               conducted with the newer versions of HAZUS.",
  journal   = "Nat. Hazards Rev.",
  publisher = "American Society of Civil Engineers",
  volume    =  7,
  number    =  2,
  pages     = "40-44",
  month     =  may,
  year      =  2006,
  url       = "https://doi.org/10.1061/(ASCE)1527-6988(2006)7:2(40)",
  keywords  = "unsafe\_joss",
  issn      = "1527-6988",
  doi       = "10.1061/(ASCE)1527-6988(2006)7:2(40)"
}

@ARTICLE{Scawthorn2006,
  title     = "{HAZUS-MH} Flood Loss Estimation Methodology. {II}. Damage and
               Loss Assessment",
  author    = "{Scawthorn Charles} and {Flores Paul} and {Blais Neil} and
               {Seligson Hope} and {Tate Eric} and {Chang Stephanie} and
               {Mifflin Edward} and {Thomas Will} and {Murphy James} and {Jones
               Christopher} and {Lawrence Michael}",
  abstract  = "Part I of this two-part paper provided an overview of the
               HAZUS-MH Flood Model and a discussion of its capabilities for
               characterizing riverine and coastal flooding. Included was a
               discussion of the Flood Information Tool, which permits rapid
               analysis of a wide variety of stream discharge data and
               topographic mapping to determine flood-frequencies over entire
               floodplains. This paper reports on the damage and loss
               estimation capability of the Flood Model, which includes a
               library of more than 900 damage curves for use in estimating
               damage to various types of buildings and infrastructure. Based
               on estimated property damage, the model estimates shelter needs
               and direct and indirect economic losses arising from floods.
               Analyses for the effects of flood warning, the benefits of
               levees, structural elevation, and flood mapping restudies are
               also facilitated with the Flood Model.",
  journal   = "Nat. Hazards Rev.",
  publisher = "American Society of Civil Engineers",
  volume    =  7,
  number    =  2,
  pages     = "72-81",
  month     =  may,
  year      =  2006,
  url       = "https://doi.org/10.1061/(ASCE)1527-6988(2006)7:2(72)",
  keywords  = "unsafe\_joss",
  issn      = "1527-6988",
  doi       = "10.1061/(ASCE)1527-6988(2006)7:2(72)"
}
